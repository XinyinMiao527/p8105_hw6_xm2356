---
title: "Homework 6"
author: "Xinyin Miao (xm2356)"
date: "2025-11-22"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(janitor)   
library(broom)     
library(purrr)  
```

# Problem 1

```{r}
homicides <- readr::read_csv("data/homicide-data.csv") |>
  clean_names() |>
  mutate(
    city_state = str_c(city, ", ", state),
    solved = if_else(disposition == "Closed by arrest", 1L, 0L),
    victim_sex  = na_if(victim_sex,  "Unknown"),
    victim_race = na_if(victim_race, "Unknown"),
    victim_age = ifelse(victim_age %in% c("Unknown", ""), NA, victim_age),
    victim_age = as.numeric(victim_age)
    ) |>
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
         victim_race %in% c("White", "Black")
         ) |>
  mutate(
    victim_sex  = factor(victim_sex,  levels = c("Female", "Male")),
    victim_race = factor(victim_race, levels = c("White", "Black"))
  )

```

## For Baltimore,MD
```{r}
baltimore <-
  homicides |>
  filter(city_state == "Baltimore, MD")

baltimore_glm <-
  glm(
    solved ~ victim_age + victim_sex + victim_race,
    data   = baltimore,
    family = binomial()
  )

```

```{r}
baltimore_results <-
  baltimore_glm |>
  tidy(
    conf.int     = TRUE,
    exponentiate = TRUE 
  )

baltimore_male_female_or <-
  baltimore_results |>
  filter(term == "victim_sexMale") |>
  select(term, estimate, conf.low, conf.high)

baltimore_male_female_or |> 
  knitr::kable(digits = 4)

# the estimate and CI of the adjusted odds ratio for solving homicides comparing male to female victims keeping all other variables fixed

```

## For each of the cities
```{r}
city_results <-
  homicides |>
  nest(data = -city_state) |>
  mutate(
    model = map(data, \(df) glm( solved ~ victim_age + victim_sex + victim_race,  data   = df, family = binomial())
    ),
    tidied = map(model, \(m) tidy(m,
        conf.int     = TRUE,
        exponentiate = TRUE
      )
    )
  ) |>
  select(city_state, tidied) |>
  unnest(tidied) |>
  filter(term == "victim_sexMale") |> 
  select(city_state, estimate, conf.low, conf.high) |> 
  arrange(desc(estimate))

city_results |> 
  knitr::kable(digits = 4)

```

## Plot
```{r city-or-plot, fig.width=8, fig.height=7}
city_results_plot <-
  city_results |>
  mutate(
    city_state = forcats::fct_reorder(city_state, estimate)
  )

city_results_plot |>
  ggplot(aes(x = estimate, y = city_state)) +
  geom_point() +
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high), width = 0) +
  geom_vline( xintercept = 1, linetype   = "dashed") +
  labs(
    x     = "Adjusted OR of solving homicide (male vs female victims)",
    y     = "City",
    title = "Adjusted odds ratios for male vs female victims by city"
  ) +
  theme_minimal()

```

The plot shows substantial variation across cities in the adjusted odds of solving homicides for male versus female victims. Although many cities have point estimates below 1—suggesting a tendency toward lower clearance odds for male victims—the confidence intervals for nearly all cities are wide and typically cross 1. Because this uncertainty is large, the apparent pattern is not statistically reliable, and we cannot confidently conclude that cases involving female victims are more likely to be solved.

# Problem 2

```{r, include=FALSE, message=FALSE, warning=FALSE}
library(p8105.datasets)
data("weather_df")
library(modelr)
```

## Bootstrap fit
```{r}
set.seed(123)

boot_results <-
  weather_df |>
  drop_na(tmax, tmin, prcp) |>
  bootstrap(n = 5000) |>
  mutate(
    model  = map(strap, ~ lm(tmax ~ tmin + prcp, data = .x)),
    glance = map(model, broom::glance),
    tidy   = map(model, broom::tidy),
    
    r_sq = map_dbl(glance, "r.squared"),

    beta_tmin = map_dbl(tidy, ~ .x |>
                          filter(term == "tmin") |>
                          pull(estimate)),
    beta_prcp = map_dbl(tidy, ~ .x |>
                          filter(term == "prcp") |>
                          pull(estimate)),

    beta_ratio = beta_tmin / beta_prcp
  )

```

## The plot of $\hat{r^2}$
```{r}
boot_results |>
  ggplot(aes(x = r_sq)) +
  geom_histogram(bins = 30) +
  labs(
    x = expression(hat(r)^2),
    y = "Count",
    title = expression("Bootstrap distribution of " * hat(r)^2)
  ) +
  theme_bw()

```

The bootstrap distribution of $\hat{r^2}$ is approximately symmetric and bell-shaped, close to a normal distribution. 

It is centered around roughly 0.94, indicating that the fitted model consistently explains about 94% of the variability in tmax across bootstrap samples and the linear association between tmax and the predictors (tmin, prcp) is consistently strong.

It also shows moderate spread, with most values falling between 0.935 and 0.945. No extreme outliers—the tails taper smoothly on both ends.



## The plot of $\frac{\hat{\beta_1}}{\hat{\beta_2}}$ 
```{r}
boot_results |>
  ggplot(aes(x = beta_ratio)) +
  geom_histogram(bins = 30) +
  labs(
    x = expression(hat(beta)[1] / hat(beta)[2]),
    y = "Count",
    title = expression("Bootstrap distribution of " * hat(beta)[1] / hat(beta)[2])
  ) +
  theme_bw()
```

The ratio $\frac{\hat{\beta_1}}{\hat{\beta_2}}$ compares the effect of minimum temperature relative to the effect of precipitation. 

The distribution is left-skewed with a long tail extending toward more negative values.

The ratio shows substantial variability, mainly because the precipitation coefficient is small and unstable across bootstrap samples.

The long left tail (–300 to –400) indicates that small changes in the prcp coefficient can produce relatively large negative ratios.

## The 2.5% and 97.5% quantiles
```{r}
boot_results |>
  summarize(
    r2_lower      = quantile(r_sq, 0.025),
    r2_upper      = quantile(r_sq, 0.975),
    ratio_lower   = quantile(beta_ratio, 0.025),
    ratio_upper   = quantile(beta_ratio, 0.975)
  ) |> 
  knitr::kable(digits = 4, caption = "95% Bootstrap Confidence Intervals")

```

# Problem 3

```{r, include=FALSE}
set.seed(123)
```

## Data import and cleaning

```{r}
birthweight_raw <- read_csv("data/birthweight.csv") |>
clean_names()

birthweight_df <- birthweight_raw |>
  mutate(
    babysex = factor(babysex, levels = c(1, 2),
                     labels = c("male", "female")),
    frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9),
                   labels = c("White", "Black", "Asian",
                              "Puerto Rican", "Other", "Unknown")),
    mrace = factor(mrace, levels = c(1, 2, 3, 4, 8),
                   labels = c("White", "Black", "Asian",
                              "Puerto Rican", "Other")),
    malform = factor(malform, levels = c(0, 1),
                     labels = c("absent", "present")))

# check NA

birthweight_df |>
summarise(across(everything(), ~sum(is.na(.)))) |>
pivot_longer(everything(),
names_to = "variable",
values_to = "n_miss") |>
filter(n_miss > 0)

```

## Model construction

```{r}
bw_model <- lm(bwt ~ babysex + bhead + blength + gaweeks +
ppbmi + ppwt + wtgain + smoken + mrace,
data = birthweight_df
)

summary(bw_model)
```

I proposed a regression model that includes the predictors `babysex`, `bhead`, `blength`, `gaweeks`, `ppbmi`, `ppwt`, `wtgain`, `smoken`, `mrace`.

Infant factors:
The model included head circumference, birth length, gestational age, and sex. These variables directly reflect fetal size, maturity, and biological differences at birth, and are consistently among the strongest predictors of birthweight.

Maternal factors:
The model incorporated pre-pregnancy BMI and weight, pregnancy weight gain, smoking during pregnancy, and maternal race. These variables capture maternal nutritional status, health behaviors, and demographic differences that are known to affect intrauterine growth.

## Residual diagnostics

```{r}
birthweight_df |>
  add_predictions(bw_model) |>
  add_residuals(bw_model) |> 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3) +
  geom_hline(yintercept = 0, linetype = "dashed")  +
  geom_smooth(se = FALSE)  + 
  labs(
    x = "Fitted values",
    y = "Residuals",
    title = "Residuals vs fitted values for birthweight model") +
  theme_bw()

```

## Cross validation

```{r}
cv_df <- crossv_mc(birthweight_df, n = 100, test = 0.2) |>
  mutate(
    train = map(train, as_tibble),
    test  = map(test,  as_tibble))

cv_models <- cv_df |>
mutate(
  mod_prop= map(train, ~ lm(bwt ~ babysex + bhead + blength + gaweeks + ppbmi + ppwt + wtgain + smoken + mrace, data = .x)),
  mod_1 = map(train, ~ lm(bwt ~ blength + gaweeks, data = .x)),
  mod_2 = map(train, ~ lm(bwt ~ bhead * blength * babysex, data = .x)))

```


```{r}
cv_results <- cv_models |>
  mutate(
    rmse_final = map2_dbl(mod_prop, test, rmse),
    rmse_mod1  = map2_dbl(mod_1,    test, rmse),
    rmse_mod2  = map2_dbl(mod_2,    test, rmse)) |>
  select(starts_with("rmse_")) |>
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse") |>
  mutate(
    model = recode(model,
                   rmse_final = "Proposed model",
                   rmse_mod1  = "Length + gestational age",
                   rmse_mod2  = "Head*Length*Sex (all interactions)"))

# summary statistics

cv_results |> 
  group_by(model) |>
  summarise(
    mean_rmse = mean(rmse),
    sd_rmse   = sd(rmse)) |> 
  arrange(mean_rmse)

```

Across 100 Monte Carlo cross-validation splits, the proposed model achieved the lowest prediction error. Its mean RMSE was approximately 273 g, compared with 288 g for the model containing all interactions among head circumference, length, and sex, and 331 g for the simple model using only birth length and gestational age.

```{r}
cv_results_sorted <- cv_results |>
  mutate(model = forcats::fct_reorder(model, rmse, .fun = median))

ggplot(cv_results_sorted, aes(x = model, y = rmse)) +
  geom_boxplot() +
  labs(
  x = "Model",
  y = "RMSE on test data",
  title = "Cross-validated prediction error for three models"
) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 20, hjust = 1))

```

The boxplots show the same pattern:

Proposed model: lowest median RMSE, smallest variability.

Interaction model: slightly higher error and greater spread, suggesting potential overfitting.

Length + gestational age model: clearly the worst predictive performance, with both higher RMSE and much larger variability across splits.





